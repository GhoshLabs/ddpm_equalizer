# -*- coding: utf-8 -*-
"""diffusion_eq.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1BbZSe-aYaeYJ4yhHIVktoHbU9_XAlNIS
"""

import torch.utils
from torch.utils.data import TensorDataset, DataLoader
import torch
import torch.nn as nn
import torchvision
from torch.nn import init
from torch.nn import functional as F
import math
import matplotlib.pyplot as plt
import matplotlib.animation as animation
from scipy.ndimage.interpolation import rotate
import numpy as np
from torch.optim import Adam

M=64
d=2
n_tx = 4
n_rx = 4
l_seq = 10

h_proak = [0.407, 0.815, 0.407]
def get_h(tx, rx, h):
    h_mat = torch.zeros(tx, rx, len(h), dtype=torch.cdouble)
    for i in range(min(tx,rx)):
        h_mat[i,i,:] = torch.tensor(h)
    #h_mat += torch.rand(h_mat.shape) + 1j*torch.rand(h_mat.shape)
    return h_mat
h = get_h(n_tx, n_rx, h_proak)
#print(h.shape)

def compute_sir(h):
    h = np.asarray(h)
    h0 = h[0]
    isi_power = np.sum(np.abs(h[1:])**2)
    signal_power = np.abs(h0)**2
    return signal_power / isi_power if isi_power > 0 else np.inf

sir_proak = compute_sir(h_proak)

T = 200
beta_0 = 0.0001
beta_T = 0.08

def plot_scatter(x):
    plt.scatter(np.real(x),np.imag(x))
    plt.show()

def beta_schedule(target_snr, T):
    """
    Compute betas such that cumulative product of alphas (bar_alpha_T)
    ends at target SNR: bar_alpha_T / (1 - bar_alpha_T) = target_snr
    """
    bar_alpha_T = target_snr / (1 + target_snr)

    # Cosine or linear SNR schedule in log space
    log_snr = np.linspace(np.log(1e6), np.log(target_snr), T)
    snr_t = np.exp(log_snr)
    bar_alpha_t = snr_t / (1 + snr_t)

    alpha_t = np.zeros(T)
    alpha_t[0] = bar_alpha_t[0]
    for t in range(1, T):
        alpha_t[t] = bar_alpha_t[t] / bar_alpha_t[t - 1]

    beta_t = 1 - alpha_t
    return beta_t

betas = torch.tensor(beta_schedule(sir_proak, T))
alphas = 1.0 - betas
alpha_bars = torch.cumprod(alphas, dim=0)

def diff_fwd(data_0, betas, T):
    fwd_seq = torch.empty((T,data_0.shape[0],data_0.shape[1]),dtype=torch.cdouble, device=data_0.device) # Add batch dimension and specify device
    fwd_seq[0,:,:] = data_0 # Assign with batch dimension
    betas = betas.to(data_0.device) # Move betas to the same device as data_0
    for t in range(T-1):
        fwd_seq[t+1,:,:] = fwd_seq[t,:,:]*torch.sqrt(1-betas[t]) + torch.sqrt(betas[t])*torch.randn_like(data_0) + 1j*torch.sqrt(betas[t])*torch.randn_like(data_0)
    return fwd_seq

'''def get_x(M, d, shape):
    a_m_list = [(2*m-1-math.sqrt(M))*d for m in range(int(math.sqrt(M)))]
    return torch.tensor(np.random.choice(a_m_list, shape) + 1j*np.random.choice(a_m_list, shape))

x = get_x(M,d, (n_tx,l_seq))
#plot_scatter(x)

x_prime = torch.zeros((max(n_tx,n_rx),l_seq+len(h_proak)-1),dtype=torch.cdouble)
x_prime[0:n_tx,0:l_seq] = x
#print(x_prime.shape)

x_T = diff_fwd(x_prime, betas, T)
#print(x_T.shape)
#plot_scatter(x_T[-1,:,:])

def get_y(x, h):
    y = torch.zeros(x.shape[0],x.shape[1], dtype=torch.cdouble)
    for i in range(y.shape[1]-h.shape[-1]):
        y[:,i:i+h.shape[-1]] += torch.matmul(torch.t(x[:,i]),h)
    return y

y = get_y(x_prime, h)
#print(y.shape)
#plot_scatter(y)

y_T = diff_fwd(y,betas,T)
#plot_scatter(y_T[-1,:,:])
y_T_rev = torch.flip(y_T, (0,))

fwd_diff_seq = torch.cat((x_T,y_T_rev), 0)
for i in range(int(fwd_diff_seq.shape[0]/40)):
    plot_scatter(fwd_diff_seq[i*40,:,:])
plot_scatter(fwd_diff_seq[-1,:,:])'''

class Datasets(torch.utils.data.Dataset):
    def __init__(self, M, d, h, n_tx, n_rx, l_seq, total_len=100):
        self.d = d
        self.M = M
        self.h = h
        self.n_tx = n_tx
        self.n_rx = n_rx
        self.l_seq = l_seq
        self.total_len = total_len

    @property
    def get_a_m_list(self):
        return [(2*m-1-math.sqrt(M))*d for m in range(int(math.sqrt(M)))]

    def __len__(self):
        return self.total_len

    def __getitem__(self, idx):
        a_m_list = [(2*m-1-math.sqrt(self.M))*self.d for m in range(int(math.sqrt(self.M)))]
        x = torch.tensor(np.random.choice(a_m_list, (self.n_tx,self.l_seq)) + 1j*np.random.choice(a_m_list, (self.n_tx,self.l_seq)), dtype=torch.cdouble) # Changed to cdouble
        data_x = torch.zeros((max(self.n_tx, self.n_rx), self.l_seq+len(self.h)-1),dtype=torch.cdouble) # Changed to cdouble
        data_x[0:n_tx,0:l_seq] = x

        return data_x

class Backbone(nn.Module):
    def __init__(self, n_steps, input_dim = (max(n_rx, n_tx), l_seq+len(h_proak)-1)):
        super().__init__()
        # Assuming input_dim is (channels, height, width) for Conv2d
        # We need to adjust input_dim to be a tuple of (channels, height, width)
        # Based on the usage, it seems input_dim is (batch_size, channels, height, width)
        # Let's assume input_dim is (height, width) and we will use 1 channel
        in_channels = 2 # Two channels for real and imaginary parts
        out_channels = 1 # Output complex number (real and imaginary parts)
        height, width = input_dim
        self.linear_model1 = nn.Sequential(
            nn.Conv2d(in_channels, 256, kernel_size=3, padding=1), # Example kernel size and padding
            nn.Dropout(0.2),
            nn.GELU()
        )
        # Condition time t
        self.embedding_layer = nn.Embedding(n_steps, 256)
        #self.embedding_layer.weight.data = self.embedding_layer.weight.data.double()


        self.linear_model2 = nn.Sequential(
            nn.Conv2d(256, 512, kernel_size=3, padding=1), # Example kernel size and padding
            nn.Dropout(0.2),
            nn.GELU(),

            nn.Conv2d(512, 512, kernel_size=3, padding=1), # Example kernel size and padding
            nn.Dropout(0.2),
            nn.GELU(),

            nn.Conv2d(512, 2, kernel_size=3, padding=1), # Output 2 channels for real and imaginary parts
        )
    def forward(self, x, idx):
        # Reshape input for Conv2d: (batch_size, channels, height, width)
        # Split complex input into real and imaginary channels
        x_real = x.real.unsqueeze(1)
        x_imag = x.imag.unsqueeze(1)
        x = torch.cat([x_real, x_imag], dim=1) # Concatenate real and imaginary parts as channels

        x = self.linear_model1(x)
        # The embedding needs to be added to the feature maps.
        # We need to expand the embedding to match the spatial dimensions of x.
        emb = self.embedding_layer(idx).unsqueeze(-1).unsqueeze(-1).expand(-1, -1, x.size(2), x.size(3))
        x = self.linear_model2(x + emb)

        # Split output channels back into real and imaginary parts and combine into complex
        x_real = x[:, 0, :, :].squeeze(1)
        x_imag = x[:, 1, :, :].squeeze(1)
        x = torch.complex(x_real, x_imag)

        return x

def get_loss(model, x_0, t):
    x_seq = diff_fwd(x_0, betas, T)
    noise = x_0 - x_seq[t,:,:]
    noise_theta = model(x_0, t)
    # Calculate MSE for complex numbers by summing the MSE of real and imaginary parts
    loss = F.mse_loss(noise.real, noise_theta.real) + F.mse_loss(noise.imag, noise_theta.imag)
    return loss

@torch.no_grad()
def sample_timestep(x, t):
    if t == 0:

        return model(x, t)

    else:
        mu_t = (torch.sqrt(alpha_bars[t-1])*betas[t]*model(x, t) + torch.sqrt(alphas[t])*(1-alpha_bars[t-1])*x)/(1-alpha_bars[t])
        beta_t_tilde = (1-alpha_bars[t-1])*betas[t]/(1-alpha_bars[t])

        return mu_t + beta_t_tilde*torch.randn_like(x) + 1j*beta_t_tilde*torch.randn_like(x)

model = Backbone(T)
model

device = "cuda" if torch.cuda.is_available() else "cpu"
model.to(device)
# Cast the model parameters to double
model = model.to(torch.double)
optimizer = Adam(model.parameters(), lr=0.001)
epochs = 100
batchsize = 10

dataloader = torch.utils.data.DataLoader(Datasets(M, d, h, n_tx, n_rx, l_seq, total_len=batchsize*100), batch_size=batchsize)

for epoch in range(epochs):
    for step, batch in enumerate(dataloader):
      optimizer.zero_grad()

      x_0 = batch[0].to(device) # Unpack the batch into x_0

      t = torch.randint(0, T, (batchsize,), device=device).long()
      loss = get_loss(model, x_0, t) # Pass only x_0 to get_loss
      loss.backward()
      optimizer.step()

      if epoch % 5 == 0 and step == 0:
        print(f"Epoch {epoch} | step {step:03d} Loss: {loss.item()} ")
        # Assuming plot_scatter is defined and works with complex numbers
        # You might need to plot real and imaginary parts separately or use a different function
        # plot_scatter(batch[0])

dataset = Datasets(M, d, h, n_tx, n_rx, l_seq)
sample_x = dataset[0] # Get the first sample
sample_y = torch.zeros(sample_x.shape[0],sample_x.shape[1], dtype=torch.double)
for i in range(sample_y.shape[1]-h.shape[-1]):
    sample_y[:,i:i+h.shape[-1]] += torch.matmul(torch.t(sample_x[:,i]),h)